[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Guillermo Romero",
    "section": "",
    "text": "As a dedicated environmental data scientist, I’ve honed my skills at the intersection of data science, geography, and machine learning.\nI hold a Master’s of Environmental Data Science from the Bren School of Environmental Science & Management, University of California, Santa Barbara. I also earned an Earth Science B.S. with a concentration in geohydrology and a Geography B.A. with a concentration in Geographic Information Systems (GIS) in 2022.\nMy primary interest lies in leveraging data science and machine learning techniques to address critical environmental and climate issues. I am particularly captivated by the potential of remote sensing and earth observation in enhancing our understanding of the environment.\nThe skills and knowledge I’ve acquired from the Bren School have prepared me to tackle a wide range of environmental challenges. Whether it’s improving resource efficiency, monitoring environmental quality in real-time, forecasting environmental changes, or assessing community resources, I am convinced that these are problems with data science at their core.\nI am excited about the opportunities that lie ahead and am committed to using data science to improve our environment and the lives of those around us. This is what I aspire to achieve professionally."
  },
  {
    "objectID": "posts/field_report/index.html",
    "href": "posts/field_report/index.html",
    "title": "Field Methods In Hydrology - Field Report",
    "section": "",
    "text": "Introduction to general field techniques used in hydrology including methods to determine river discharge,basic well and spring sampling, well water level measurements, and soil hydraulic characterization. The ~1 week course took place at Sagehen Creek Field Station (north of Truckee, CA) in the eastern Sierra prior to the start of the 2021 Fall quarter under the guidance of Prof. Jordan Clark and teaching assistant Shelby Smith.\nView and Download Writing Sample Here"
  },
  {
    "objectID": "posts/map_gallery/index.html",
    "href": "posts/map_gallery/index.html",
    "title": "Map Gallery",
    "section": "",
    "text": "First Poster Created for an “Introduction to GIS” course created with ArcMap.\n\n\n\n\n\n\n\nA geologic map over Aster satellite imagery made with provided field notes, satellite imagery and some spectral data from the satellite-based ASTER instrument to figure out the distribution of rock units.\n\n\n\n\n\n\n\nJohn Snow\nRecreation of the pivotal John Snow map of cholera outbreak.\n\n\n\n\n\n\n\nCreated for Cartographic Design and Geovisualization course.\n\n\n\n\n\n\n\nGeocoding and Digitizing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChloropleth, Kriging, and IDW mapping"
  },
  {
    "objectID": "posts/redlining_NDVI/index.html",
    "href": "posts/redlining_NDVI/index.html",
    "title": "Analyzing Greenness through NDVI in Redlined areas in Philadelphia, Pennsylvania",
    "section": "",
    "text": "Introduction\n‘Redlining’ is the term used for the racist, nativist, and class privileged maps and its grading system created by the Home Owners Loan corporation (HOCL) under the New Deal federal stimulus program of 1935. These HOCL grades and maps were used by mortgage lenders for decades furthering racial segregation and a disparity in financial resources\\(^1\\).\n\nIn this study, we first try to see if there are any relationships between these redlined areas and greenness in Philadelphia, Pennsylvania. We used Landsat 4-5 TM and Landsat 8-9 OLI/TIRS Collection Level-2 to:\n\nCompare how vegetation coverage has changed over the span of 4 decades: 1990, 2000, 2010, and 2020.\nUse NDVI as a measure for greenness and vegetation coverage.\n\nWe will also look at different socioeconomic variables to see how redlined areas and NDVI can affect:\n\nIncome\\(^2\\)\nNumber of people with disabilities in an area\\(^3\\)\nWe will use census tract data for this part of the study\n\nResearch Questions:\n● How does NDVI change across 4 decades in redlined areas?\n● How does NDVI change with income in redlined areas?\n● How does NDVI change with disability status in redlined areas?\nHypotheses:\n● Areas with a high HOLC Redlining grade, there will be a higher mean NDVI\n● NDVI will increase in “D” graded areas as median income increases.\n● Areas with higher NDVI will have lower reports of people with a disability; areas with lower NDVI will have higher reports of people with a disability\n\n\nMethods\n\n\n\nHOCL Grades\nRedlining is a discriminatory practice that assigned neighborhood gradings (A-D) based on desirability\\(^1\\):\nA = Best\nB = Still Desirable\nC = Declining\nD = Hazardous\nMortgage lender denied loans and/or restricted services to certain areas of a community, often because of the racial characteristics of the applicant’s neighborhood included into the grading such as:\n• “Undesirable negro section of very poor property”\n• “Concentration of undesirables. Low class whites and negro”\n\n\n\nRedline regions were overlayed over Philadelphia to determine areas of analysis\n\n\n\n\nGreenness Over Time, 1990 - 2020\nChange detection of vegetation was performed by loading 1990 mean NDVI in red channel and 2020 mean NDVI in blue and green channels.\n\n2020 increases in vegetation are observed in central region and Northwest and Southeast boundaries Urban areas in southern portion show very little change of vegetation on both sides of river since 1990\n\n\n\nFigure 1: Comparison of average NDVI and percent difference show all areas experience a decrease in NDVI with Grade “A” regions exhibiting the most loss followed by “D” grade regions\n\n\n\n\nNDVI and Household Median Income\nThe analysis was performed by selecting only areas ‘A’, ‘D’, and the areas outside the redlining to compare the relationship between NDVI and Median Income in 1990, 2000, 2010, and 2020.\nIn 1990, the NDVI was higher (≈ 0.25 – 0.4), and median income was lower (≈ $ 25,000). In 2000, the NDVI started to continuously decrease (≈ 0.18 – 0.27) till 2020 in all areas, as median income keeps increasing (≈ $ 54,000).\n\n\n\n\nFigure 2: The correlation between mean NDVI and median household income is inversely proportional. As income increases, NDVI decreases in the three areas over the decades.\n\n\nChange in NDVI between 1990 and 2020 becomes less linear since the Census tracts that lost the most greenness was composed of areas ‘A’. While areas ‘D’ experienced a smaller, but still significant, decrease in greenness as well.\n\n\n\n\nFigure 3: Average NDVI and the median income of each redline block that comprises areas ‘A’ and ‘D’.\n\n\n\n\nNDVI and Disability\nFive different study areas:\n• D Group\n• A Group\n• Census tract that lies outside of Redline area\n• D Group based on HOLC grade\n\nResults:\n• D Group has lowest mean NDVI, and high number of disabled people compared to A Group\n• A Group has highest mean NDVI and lowest number of disability reports\n• In the urban center, also has low NDVI and high number of disabilities reported\n\n\n\nFigure 4: Graph showing both the mean NDVI in 2020 with the red line and the number of disability reports in 2020 with the blue bar\n\n\n\n\nConclusion\nFor general trends, the data showed that average NDVI for areas with a grade of “A” showed the most loss over 4 decades. Areas graded “D” showed nearly the same amount of NDVI difference despite initially having much lower NDVI values in 1990. Median Household Income increases with lower mean NDVI values: this holds true in areas A, D and non-redlined zones. This is consistent with the findings from Casey et al. proving how urban greenness is unequally distributed with neighborhood demographics. Disability, followed areas of greater redlining (lower grades) and areas of lower NDVI values. Within redlined areas, all areas with “A” grades have significantly higher NDVI values, higher medium income and lower disability rates than all areas with a “D” grade. Overall, the presence of green areas in urban spaces have positive impacts to the individual, including lower rates of disabilities and higher median income levels. Areas that are within the redlined boundaries experience these lower standards of living compared to areas that are not redlined. City planners and local/state governments should increase greenness and promote social equity goals, especially in these disadvantaged communities.\n\n\nReferences\n\nNardone, Anthony, et al. “Redlines and Greenspace: The Relationship between Historical Redlining and 2010 Greenspace across the United States.” National Institute of Environmental Health Sciences, U.S. Department of Health and Human Services, 27 Jan.2021, https://ehp.niehs.nih.gov/doi/10.1289/EHP7495.\nCasey, J.A.; James, P.; Cushing, L.; Jesdale, B.M.; Morello-Frosch, R. Race, Ethnicity, Income Concentration and 10-Year Change in Urban Greenness in the United States. Int. J. Environ. Res. Public Health 2017, 14, 1546, doi.org/10.3390/ijerph14121546\nZhu, Anna et al. “Residential greenness, activities of daily living, and instrumental activities of daily living: A longitudinal cohort study of older adults in China.” Environmental epidemiology (Philadelphia, Pa.) vol. 3,5 e065. 14 Oct. 2019, doi:10.1097/EE9.0000000000000065"
  },
  {
    "objectID": "posts/SentinelNBR/index.html",
    "href": "posts/SentinelNBR/index.html",
    "title": "Burn Severity with Sentinel-2 data using Google Earth Engine",
    "section": "",
    "text": "THIS POST IS TO SHOWCASE SOME PYTHON WORK DONE IN JUPYTER NOTEBOOK. CONVERTING TO QUARTO HAS CAUSED SOME INCOMPATABILITY SO SCREENSHOTS HAVE BEEN ADDED OF MAPS. ORIGINAL JUPYTER REPOSITORY CAN BE FOUND AT romero61/eds220-burn-scar-analysis: EDS 220 final group project (github.com)\nIn this Jupyter Notebook, we first visualize true color images of the August Complex fire before and after it burned. Bands from the Sentinel 2 satellites as well as a dataset from USFS with wildfire boundaries are used for our analysis. Then, the Normalized Burn Ratio (NBR) is used to analyze burn severity, which is a measure of the degree to which a fire has affected the ecosystem. To compare these two images, we will compute the normalized difference to show where burn severity most significantly affected the vegetation and soil. We then added a scale to the normalized difference to show the levels of burn severity from the August Complex fire. Finally, we visualized the levels of severity to show the overall intensity. This link provides more information on the Sentinel 2 dataset that was used: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2."
  },
  {
    "objectID": "posts/SentinelNBR/index.html#nbrs-in-greyscale",
    "href": "posts/SentinelNBR/index.html#nbrs-in-greyscale",
    "title": "Burn Severity with Sentinel-2 data using Google Earth Engine",
    "section": "NBRs in greyscale",
    "text": "NBRs in greyscale\nThe Normalized Burn Ratio (NBR) is the ratio between NIR and SWIR, as shown by the equation below:\n\n\n\nimage.png\n\n\nThe Normalized Burn Ratio (NBR) is used to highlight burned areas and estimate burn severity, using near-infrared (NIR) and shortwave-infrared (SWIR) wavelengths. Healthy vegetation has very high NIR reflectance and low SWIR. Recently burned areas have a low NIR reflectance and high SWIR reflectance.\nThe spectral response curves of healthy vegetation versus burned vegetation is shown below. Since the two reach peak differences in the NIR and SWIR wavelengths, we can calculate the ratio of this difference to focus on where the August Complex fire burned.\n\n\n\nimage.png\n\n\nPreparing pre-fire and post-fire Normalized Burn Ratio (NBR) images:\n\npreNBR = pre_cm_mos.normalizedDifference(['B8', 'B12']);\npostNBR = post_cm_mos.normalizedDifference(['B8', 'B12']);"
  },
  {
    "objectID": "posts/SentinelNBR/index.html#creating-an-interactive-map-of-pre-fire-and-post-fire-nbrs",
    "href": "posts/SentinelNBR/index.html#creating-an-interactive-map-of-pre-fire-and-post-fire-nbrs",
    "title": "Burn Severity with Sentinel-2 data using Google Earth Engine",
    "section": "Creating an interactive map of pre-fire and post-fire NBRs",
    "text": "Creating an interactive map of pre-fire and post-fire NBRs\n\n\n\nimage.png\n\n\n\n#Burn Ratio Product - Greyscale\ngrey = ['white', 'black'];\nleft_layer = geemap.ee_tile_layer(preNBR, {'min': -1, 'max': 1, 'palette': grey}, 'Prefire Normalized Burn Ratio')\nright_layer = geemap.ee_tile_layer(postNBR, {'min': -1, 'max': 1, 'palette': grey}, 'Postfire Normalized Burn Ratio')\n\nMaps =  geemap.Map(center=[39.9, -122.9], zoom=8.7)\n\nMaps.split_map(left_layer, right_layer)\nMaps"
  },
  {
    "objectID": "posts/SentinelNBR/index.html#adding-burn-severity-map-with-levels-of-severity",
    "href": "posts/SentinelNBR/index.html#adding-burn-severity-map-with-levels-of-severity",
    "title": "Burn Severity with Sentinel-2 data using Google Earth Engine",
    "section": "Adding Burn Severity map with levels of severity",
    "text": "Adding Burn Severity map with levels of severity\n\n\n\nimage.png\n\n\nA higher value of dNBR indicates more severe damage, while areas with negative dNBR values may indicate regrowth following a fire.\nTable 1. Burn severity levels obtained calculating dNBR, proposed by USGS. \n\ndNBR_unscaled = preNBR.subtract(postNBR);\n\n#Scale product to USGS standards\ndNBR = dNBR_unscaled.multiply(1000);\n\n\n\n\nimage.png\n\n\n\nMap2 = geemap.Map(center=[39.9, -122.9], zoom=8.7)\nMap2\n\n\n\n\n\nMap2.add_basemap('SATELLITE')\n\n\n# dNBR greyscale\nMap2.addLayer(dNBR, {'min': -1000, 'max': 1000, 'palette': grey}, 'dNBR greyscale');\n\n\n#Define an SLD style of discrete intervals to apply to the image.\nsld_intervals = '&lt;RasterSymbolizer&gt;' + '&lt;ColorMap type=\"intervals\" extended=\"false\" &gt;' + '&lt;ColorMapEntry color=\"#ffffff\" quantity=\"-500\" label=\"-500\"/&gt;' + '&lt;ColorMapEntry color=\"#7a8737\" quantity=\"-250\" label=\"-250\" /&gt;' + '&lt;ColorMapEntry color=\"#acbe4d\" quantity=\"-100\" label=\"-100\" /&gt;' + '&lt;ColorMapEntry color=\"#0ae042\" quantity=\"100\" label=\"100\" /&gt;' + '&lt;ColorMapEntry color=\"#fff70b\" quantity=\"270\" label=\"270\" /&gt;' + '&lt;ColorMapEntry color=\"#ffaf38\" quantity=\"440\" label=\"440\" /&gt;' + '&lt;ColorMapEntry color=\"#ff641b\" quantity=\"660\" label=\"660\" /&gt;' + '&lt;ColorMapEntry color=\"#a41fd6\" quantity=\"2000\" label=\"2000\" /&gt;' + '&lt;/ColorMap&gt;' + '&lt;/RasterSymbolizer&gt;';\n\n\nMap2.addLayer(dNBR.sldStyle(sld_intervals), {}, 'dNBR classified');\n#==========================================================================================\n#                                   ADD A LEGEND\n\nlegend_dict = {\n    \"Enhanced Regrowth, High\": '7a8737',\n    'Enhanced Regrowth, Low':  'acbe4d',\n    'Unburned': '0ae042',\n    'Low Severity': 'fff70b',\n    'Moderate-low Severity': 'ffaf38',\n    'Moderate-high Severity': 'ff641b',\n    'High Severity': 'a41fd6',\n    'NA': 'ffffff'}\n\n\nMap2.add_legend(legend_title = \"dNBR Classes\", legend_dict = legend_dict)\n\n\n ## Derive extent of burn severity classes\n\n\nthresholds = ee.Image([-1000, -251, -101, 99, 269, 439, 659, 2000]);\nclassified = dNBR.lt(thresholds).reduce('sum').toInt();\n\n\n#count number of pixels in entire layer\nallpix =  classified.updateMask(classified); #mask the entire layer\n\n\npixstats = allpix.reduceRegion(\n    reducer = ee.Reducer.count(),               # count pixels in a single class\n    geometry = aug_complex.geometry(),\n    scale = 30, \n    maxPixels = 10000000);\n\n\nallpixels = ee.Number(pixstats.get('sum')); # extract pixel count as a number\n\n\n#create an empty list to store area values in\narealist = [];\n\n\n# create a function to derive extent of one burn severity class\n#arguments are class number and class name\ndef areacount(cnr, name):\n    singleMask =  classified.updateMask(classified.eq(cnr)); # mask a single class // count pixels in a single class\n    stats = singleMask.reduceRegion(reducer = ee.Reducer.count(), geometry = aug_complex.geometry(), scale = 30, \n    maxPixels = 10000000);\n    pix =  ee.Number(stats.get('sum'));\n    hect = pix.multiply(900).divide(10000);               #Landsat pixel = 30m x 30m --&gt; 900 sqm\n    perc = pix.divide(allpixels).multiply(10000).round().divide(100);   # get area percent by class and round to 2 decimals\n    arealist.append({'Class': name, 'Pixels': pix, 'Hectares': hect, 'Percentage': perc});\n\n# severity classes in different order\nnames2 = ['NA', 'High Severity', 'Moderate-high Severity',\n'Moderate-low Severity', 'Low Severity','Unburned', 'Enhanced Regrowth, Low', 'Enhanced Regrowth, High'];\n\n\ni = 0\nfor i in range(len(names2)):\n    if i &lt; 8:\n        areacount(i, names2[i])\n        i + 1;\n\n\narealist\n\n[{'Class': 'NA',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c91d8e0&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c91d490&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c8e95b0&gt;},\n {'Class': 'High Severity',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c8e9df0&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c8d5c10&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c84e4f0&gt;},\n {'Class': 'Moderate-high Severity',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c8fc040&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c8fc370&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c7b5550&gt;},\n {'Class': 'Moderate-low Severity',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c9be460&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c9be370&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c9be5b0&gt;},\n {'Class': 'Low Severity',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c9a9c10&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c9a9fd0&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c9a9760&gt;},\n {'Class': 'Unburned',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c9d72b0&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c9d7430&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c9d7670&gt;},\n {'Class': 'Enhanced Regrowth, Low',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c9d7a30&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c9d7bb0&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c9d7df0&gt;},\n {'Class': 'Enhanced Regrowth, High',\n  'Pixels': &lt;ee.ee_number.Number at 0x11c9e51f0&gt;,\n  'Hectares': &lt;ee.ee_number.Number at 0x11c9e5370&gt;,\n  'Percentage': &lt;ee.ee_number.Number at 0x11c9e55b0&gt;}]\n\n\n\ntest = pd.DataFrame(arealist)\nprint(test)\n\n                     Class                                             Pixels  \\\n0                       NA  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n1            High Severity  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n2   Moderate-high Severity  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n3    Moderate-low Severity  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n4             Low Severity  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n5                 Unburned  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n6   Enhanced Regrowth, Low  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n7  Enhanced Regrowth, High  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n\n                                            Hectares  \\\n0  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n1  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n2  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n3  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n4  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n5  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n6  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n7  ee.Number({\\n  \"functionInvocationValue\": {\\n ...   \n\n                                          Percentage  \n0  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n1  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n2  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n3  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n4  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n5  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n6  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n7  ee.Number({\\n  \"functionInvocationValue\": {\\n ...  \n\n\n\n# Theres probably an easier way to extract the values but this works\n# pop each class into its own variable, then create a dictionary that uses .getInfo() on each value to convert from ee.Number to number\n\n#NA = arealist[0:1].pop()\n#High_Severity = arealist[0:2].pop()\n#Moderate_high_Severity = arealist[0:3].pop()\n#Moderate_low_Severity = arealist[0:4].pop()\n#Low_Severity = arealist[0:5].pop()\n#Unburned = arealist[0:6].pop()\n#Enhanced_Regrowth_Low = arealist[0:7].pop()\n#Enhanced_Regrowth_High = arealist[0:8].pop()\n\n\n# Takes quite  a while to run, so for the presentation I copied the results \n\n#stats = {'Class': ['NA', 'High Severity', 'Moderate-high Severity', 'Moderate-low Severity', 'Low Severity', 'Unburned', 'Enhanced Regrowth, Low', 'Enhanced Regrowth, High'], \n#  'Pixels': [NA['Pixels'].getInfo(), High_Severity['Pixels'].getInfo(), Moderate_high_Severity['Pixels'].getInfo(), Moderate_low_Severity['Pixels'].getInfo(), Low_Severity['Pixels'].getInfo(), Unburned['Pixels'].getInfo(), Enhanced_Regrowth_Low['Pixels'].getInfo(), Enhanced_Regrowth_High['Pixels'].getInfo() ],\n#  'Hectares': [NA['Hectares'].getInfo(), High_Severity['Hectares'].getInfo(), Moderate_high_Severity['Hectares'].getInfo(), Moderate_low_Severity['Hectares'].getInfo(), Low_Severity['Hectares'].getInfo(), Unburned['Hectares'].getInfo(), Enhanced_Regrowth_Low['Hectares'].getInfo(), Enhanced_Regrowth_High['Hectares'].getInfo()],\n#  'Percentage': [NA['Percentage'].getInfo(), High_Severity['Percentage'].getInfo(), Moderate_high_Severity['Percentage'].getInfo(), Moderate_low_Severity['Percentage'].getInfo(),Low_Severity['Percentage'].getInfo(), Unburned['Percentage'].getInfo(), Enhanced_Regrowth_Low['Percentage'].getInfo(),Enhanced_Regrowth_High['Percentage'].getInfo()]}\n\n\nstats = {'Class': ['NA',\n  'High Severity',\n  'Moderate-high Severity',\n  'Moderate-low Severity',\n  'Low Severity',\n  'Unburned',\n  'Enhanced Regrowth, Low',\n  'Enhanced Regrowth, High'],\n 'Pixels': [0, 1067623, 989630, 968749, 1061877, 1522197, 427507, 237862],\n 'Hectares': [0,\n  96086.07,\n  89066.7,\n  87187.41,\n  95568.93,\n  136997.73,\n  38475.63,\n  21407.58],\n 'Percentage': [0, 17.01, 15.77, 15.44, 16.92, 24.26, 6.81, 3.79]}\ndf_stats = pd.DataFrame(stats).set_index('Class')\ndf_stats\n\n\n\n\n\n\n\n\nPixels\nHectares\nPercentage\n\n\nClass\n\n\n\n\n\n\n\nNA\n0\n0.00\n0.00\n\n\nHigh Severity\n1067623\n96086.07\n17.01\n\n\nModerate-high Severity\n989630\n89066.70\n15.77\n\n\nModerate-low Severity\n968749\n87187.41\n15.44\n\n\nLow Severity\n1061877\n95568.93\n16.92\n\n\nUnburned\n1522197\n136997.73\n24.26\n\n\nEnhanced Regrowth, Low\n427507\n38475.63\n6.81\n\n\nEnhanced Regrowth, High\n237862\n21407.58\n3.79\n\n\n\n\n\n\n\n ### Use Case Discussion\nWe found that nearly half of the burned area was determined to be between Moderate-Low to High severity. Additionally, the High severity area was the second largest percentage of area classified.\n\ndf_stats['Hectares'].sort_values().plot.bar(color = ['gold', 'olive', 'darkkhaki'  , 'orange', 'orangered', 'yellow','purple', 'springgreen' ], width = 0.75)\nplt.ylabel('Hectares')\nplt.title('Burn Severity Analysis of 2020 August Complex Fire')\n\nText(0.5, 1.0, 'Burn Severity Analysis of 2020 August Complex Fire')\n\n\n\n\n\n\n# Pie Chart of Percentage by Class\ndf_stats.plot(kind = 'pie', y = 'Percentage',\n              colors = ['floralwhite', 'purple', 'orangered'  , 'orange', 'yellow', 'springgreen','darkkhaki', 'olive' ],\n             legend= False)\nplt.title('Burn Severity Analysis of 2020 August Complex Fire')\n\nText(0.5, 1.0, 'Burn Severity Analysis of 2020 August Complex Fire')\n\n\n\n\n\n ### Future Analyses\nWith more time, the data extracted could be analyzed with other characteristics of the environment, such as slope, aspect, wind direction, and humidity. These analyses would better inform wildfire researchers the nature of fires, how they spread, and what characteristics increase severity.\nAdditionally, this burn severity map can be compared to other wildfire burn severity maps as a function of time to see if the severity of the burns is getting worse. This would help inform wildfire researchers determine how quickly fires are increasingly negatively affecting the environment. Burn severity can also be compared temporally so that wildfire prevention can be implemented to the parts of the state most at risk.\n ### References\n\nSentinel data GEE page: https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\nUSFS MTBS Shapefile GEE page: https://developers.google.com/earth-engine/datasets/catalog/USFS_GTAC_MTBS_burned_area_boundaries_v1#description\nMTBS Project Page: https://www.mtbs.gov/\nStep by Step: Burn Severity mapping in Google Earth Engine https://code.earthengine.google.com/b455ba8cf4b5bee822bb7ff8935e6209"
  },
  {
    "objectID": "posts/SMB/index.html",
    "href": "posts/SMB/index.html",
    "title": "Remote Sensing of Chlorophyll-a Using Landsat 8",
    "section": "",
    "text": "Introduction\nThe research performed by Trinh et al. (2017) is centered on the capabilities of Landsat 8 OLI and Aqua MODIS to monitor water quality in the Santa Monica Bay (SMB). The water quality of the Santa Monica Bay is directly impacted by the adjacent Hyperion Treatment Plant (HTP), which discharges treated wastewater into its coastal waters. Wastewater discharge increases contaminant and nitrogen concentrations,which increase the likelihood of phytoplankton blooms and contaminant exposures. The phytoplankton biomass in the surface ocean is assessed by remotely sensing chlorophyll-a (chl-a) pigments within phytoplankton. To monitor the water quality impacted by wastewater discharge of the HTP, the researchers argue that the algorithms applied to remote sensing data to measure chlorophyll-a concentrations should be derived locally as opposed to the broad empirical algorithms used in the standard products of chlorophyll-a concentrations. A planned shutdown of the HTP in 2015, known as a diversion event, directly discharged wastewater 1-mile offshore in the shallow waters of the SMB instead of the ordinarily 5-mile outfall. The research uses the diversion event as a backdrop to assess Landsat 8 OLI and Aqua MODIS in their capability to measure chlorophyll-a concentrations using local vs. empirical algorithms and detect wastewater plumes.\nThe analysis of the SMB during increased wastewater discharge in shallow waters is expanded by applying the findings of Trinh et al. to the July 11th, 2021, HTP failure in creating a time series of the SMB. At the time of the incident, 17 million gallons of untreated sewage were released 1-mile offshore, with reports of the plant operating at a diminished capacity several months after the initial failure.\n\n\nData\nIn-situ measurements of the study were taken before, during, and after the wastewater diversion event along a grid of 13 stations between August 26th and November 11th and, when possible, coinciding during satellite overpass in the SMB. At all stations, hydrographic profiles were collected using an SBE 19-plus Conductivity-Temperature-Depth package with chlorophyll fluorescence collected from 1m below the surface to 1m above the ocean floor. In-situ surface chlorophyll-a concentrations were derived from water samples taken on ten different dates at selected stations. Water samples were taken at 1 meter and analyzed fluorometrically for chl-a in a laboratory using a non-acidification method for 96 measurements. In-situ hyperspectral remote sensing reflectance was measured and derived from field measurements of spectral downwelling and upwelling irradiance using a Satlantic HyperPRO free-falling optical profiler equipped with a surface irradiance reference for a total of 49 measurements on nine separate dates. Level 1 satellite data was acquired from Landsat 8 from OLI, TIRS sensors, and level 1 satellite data from Aqua MODIS, TIR sensors.\nThe analysis extension uses Landsat 8 OLI Level-2 surface reflectance products on six dates from June 6th to November 11th, 2021. Level-2 products are corrected for the temporally, spatially, and spectrally varying scattering and absorbing effects of atmospheric gases,aerosols, and water vapor. All images acquired from USGS are centered on 33°10’36.66”N – 118°42’58.32”W, on path 41 row 37 with a WGS84 datum and ellipsoid, on a U1TM Zone 11 projection.\n\n\nMethod\nUsing 36 measurements of in-situ data, two local chl-a algorithms were developed using respective blue and green wavebands of OLI and MODIS, where the natural log values of the measured surface chl-a concentrations are regressed on the natural log values of blue-green surface reflectance ratios (Figure 1).\n\nMODIS satellite data were used to produce a standard 1-km OC3M product (OC3M algorithm), a regional product (CALFIT algorithm), and application of their own locally derived algorithm to produce chl-a concentrations. Landsat 8 data retrievals from USGS were used to produce a standard OC2 chl-a product and application of their own locally derived algorithm to produce chl-a concentrations. To assess the accuracy of Landsat 8 (OC2) and MODIS (OC3M, CALFIT) algorithms to estimate chl-a concentrations, each algorithm was used with their respective blue-green wavebands (Figure 1) from in-situ measurements and compared to in-situ chl-a concentrations. Landsat 8 and MODIS surface reflectance data were applied to standard algorithms and the researcher’s local algorithm and compared against in-situ chl-a concentrations. A time-series analysis was completed using the local chl-a algorithm for OLI in which maximum chl-a concentrations for each OLI scene were found within Santa Monica Bay. Sea surface temperatures. Level 1 products of Landsat 8 and Aqua MODIS data were atmospherically corrected using a standard multi-scattering, radiative transfer model (TIRS), and iterative near-infrared (NIR) model (TIR). TIRS temperature was retrieved by inverting the atmospherically, and emissivity corrected TIRS radiances using a look-up table. Due to limitations of both OLI and MODIS accuracy and spatial extent of MODIS TIR, TIRS is only used to detect relative SST differences between plume and non-plume waters.\nThe extension of the analysis acquired images in 2021 on six different dates, July 6th and 22nd, August 7th, October 10th and 26th, and November 11th. The images acquired were the best available in the study area without cloud cover. Pre-processing was performed in R using library packages “rgdal” and “raster” the images of surface reflectance of bands 2-7 were stacked together by date. Each image was masked and cropped using a custom Shapefile derived from a Los Angeles County Shapefile, limiting the extent to the coastal waters of the SMB up to the coastline. Erroneous pixel values that do not fall within the valid range for the Landsat surface reflectance product were overwritten; the valid range for all bands 1-7 is 7273-43636. The scale factor of the images was changed to 100. A time-series analysis was produced using the researchers’ local OLI algorithm of chl-a concentrations applying blue and green bands of each image data and exported for use in Qgis.\n\n\nResults\nWastewater plume detection via sea surface temperature (SST) was clearly detected by Landsat 8 TIRS, showing the relative temperature difference between the wastewater plume and ambient waters. Before and after the diversion event, no SST anomalies were detected; during the diversion event, at the 1- mile outfall pipe, decreased SSTs were clearly detected ~1 °C colder than the surrounding water. Comparisons to in-situ data were not provided due to TIRS SST data providing skin surface temperature measurements of the top few millimeters of the ocean surface, and in-situ measurements were taken at depths greater than 1m below the surface.\nThe results of comparing estimated chl-a using standard algorithms and in-situ reflectance were reported as mean percent errors between estimated chl-a values and in-situ values. The OC2 algorithm had a ±40% mean percent error, the paper’s OLI local algorithm yielding a ±30% mean percent error using in-situ reflectance. The OC3M algorithm resulted in a ±35% mean percent error, with the regional CALFIT algorithm reported as more accurately estimating chl-a values but greatly overestimating high chl-a values. The derived local MODIS algorithm using in-situ reflectance resulted in estimated values with a mean percent error of ±32% of in-situ chl-a values. The standard algorithms tended to underestimate mid-level chl-a values and overestimate high chl-a values with respect to measured values, with the highest values falling well above the +30% error. The researcher’s local OLI algorithm was the best performing algorithm, with the lowest mean percent error and more accurate estimated chl-a values.\nThe researchers used the scenes of Landsat 8 and MODIS on November 11th, 2015, to apply both the local algorithm and the standard chl-a algorithms, as this was the only day the satellite data coincided with in-situ reflectance and chl-a measurements (Figure 2). Overall, OLI chl-a retrievals were more accurate than MODIS. The local OLI chl-a algorithm outperformed MODIS (local and OC3M) and OC2 algorithms with a mean percent error of ∼29% and the smallest RMSE of ∼0.36. The standard OC2 algorithm underestimated chl-a values and had a mean percent error of ∼26% and RMSE of ∼0.58. The local MODIS chl-a algorithm performed better than the OC3M algorithm but still overestimated chl-a concentrations with a mean percent error of ∼37% and RMSE of ∼0.67. The standard OC3M algorithm had a mean percent error of ∼349% and RMSE of∼18.2, performing order of magnitude poorer than the local MODIS chl-a algorithm and either OLI algorithm (local or OC2). Establishing that the researchers Local OLI algorithm performed best, a time series analysis was used to evaluate the chlorophyll-a evolution in response to the wastewater diversion event (Figure 2).\n\nThe time series analysis was extended to observe the chlorophyll-a evolution in response to the HPT failure on July 11th, 2021(Figure 3). An initial 17 million gallons (5 million were pumped back) of untreated sewage was discharged through the 1-mile outfall pipe, shown on the researcher’s time series as the shorter black line. Reports indicate that the plant operated at a diminished capacity afterward. To show the evolution of chlorophyll-a, the main images are set to the scale of 7-22, using a cumulative count cut of 2%- 98% to filter out outliers in minimum and maximum values. The top end of the green portion of the scale represents an ~3.0 mg m-3, comparable to the researcher’s time-series scale. The top inset of each image uses individual scales, using a cumulative count cut of 2%- 98% to filter out outliers in minimum and maximum values. Each image’s bottom inset uses a cumulative count cut of 2%- 94% using a true-color image emphasizing the ocean color.\n\nThe first image before HTP failure shows elevated chlorophyll-a beginning ~3-miles offshore at ~3.0 mg m-3 with pockets of higher values. The results on 07-22, eleven days after failure, are obfuscated by sporadic cloud coverage; despite this, there is evidence of elevated values of chl-a up against the coastline. In-situ measurements of chl-a concentrations could not be located to corroborate due to Covid-19 sampling restrictions; the only supporting evidence is a graph of Harmful algal blooms (HABs) (Figure 4) of Pseudo-nitzschia measured shortly up thecoast at the Santa Monica Pier. HABs of Pseudo-nitzschia can cause diseases and death in many marine organisms and the humans who consume them. HABs can result in oxygen depletion caused by increased biomass production (Timmerman, 2019). On 8-22, twenty-seven days after the massive HTP failure, chl-a concentration is still exceedingly high along the coastline. The final three images show an average of 1.74 mg m-3 along the coastline when compared to the researcher’s scale is still on the high end. The November spike of Pseudo-nitzschia supports that the diminished capacity of HTP may have influenced any natural variations of phytoplankton biomass.\n\n\n\nFigure 4: Measurements of HABs from Southern California Coastal Ocean Observing System. The focus is on July and November spikes.\n\n\n\n\nSummary\nThe researcher’s central finding is that applying their local chl-a algorithms, developed using in situ chl-a and in-situ reflectance measurements improves chl-a retrievals in the SMB during the 2015 HTP wastewater diversion in comparison to the standard open ocean algorithms. The paper also demonstrates the improved accuracy of chl-a from high-resolution OLI compared to coarser resolution MODIS for coastal chl-a detection. The researcher’s study was the first to use high-resolution Landsat 8 TIRS and OLI for coastal water quality monitoring of wastewater diversions. The extension of the analysis uses the researcher’s improved accuracy to measure the chl-a concentration in response to the HTP failure of 2021. Limited corroborating measurements limited the analysis to visual interpretation. Spatial-Temporal changes in chl-a concentrations are indicative of the possible effect of the 17 million gallons of untreated wastewater discharged into SMB. Further studies can apply these findings to a more in-depth analysis of the damage to the coastal water quality of the SMB and its effect on its marine ecosystems.\n\n\nReferences\nTimmerman, R. (2021, April 9th). California HAB Bulletin: March 2021 | Southern California Coastal Ocean Observing System. Sccoos.org. https://sccoos.org/california-hab-bulletin/march-2021/\nTrinh, R. C., Fichot, C. G., Gierach, M. M., Holt, B., Malakar, N. K., Hulley, G., & Smith, J. (2017). Application of Landsat 8 for Monitoring Impacts of Wastewater Discharge on Coastal Water Quality. Frontiers in Marine Science, 4. https://doi.org/10.3389/fmars.2017.00329\n(2022). Hyperion 2021 Recovery (lacitysan.org)"
  },
  {
    "objectID": "posts/stats_project/index.html#hocl-redlining",
    "href": "posts/stats_project/index.html#hocl-redlining",
    "title": "Statistical Analysis of NDVI in Redlined Regions",
    "section": "HOCL ‘Redlining’",
    "text": "HOCL ‘Redlining’\n‘Redlining’ is the term used for the racist, nativist, and class privileged maps and its grading system created by the Home Owners Loan corporation (HOCL) under the New Deal federal stimulus program of 1935. These HOCL grades and maps were used by mortgage lenders for decades furthering racial segregation and a disparity in financial resources\nA = Best\nB = Still Desirable\nC = Declining\nD = Hazardous\nExample of language used to describe region D: • “Undesirable negro section of very poor property”\n• “Concentration of undesirables. Low class whites and negro”\n\nQuestionDataAnalysis plan\n\n\nGreenness or green space is reflective of many different measures of quality of life, such as health disparities, racial residential segregation and urban heat islands, noise pollution, air quality, and lower income.\nUsing NDVI as a measure of greenness, the question is: How does NDVI change with income in the graded regions A and D of redlined maps in Philadelphia, PA?\n\n\n\n\n\n\n\n\nCalculate median NDVI for the years 1990, 2000, 2010, 2020 by U.S. census tract in each graded region.\nMedian Income by tract from U.S. Census\n\n\n\n\n\n\n\n\n\nExplore data\nOLS to examine if there is statisically significant relationship of income & grading on NDVI\nHypothesis testing comparing Mean NDVI based on grading and year."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Analyzing Greenness through NDVI in Redlined areas in Philadelphia, Pennsylvania\n\n\nUniversity of California, Santa Barbara, Department of Geography - Undergrad Remote Sensing Group Poster Presentation\n\n\n\n\n\n\n\n\n\n\n\nStatistical Analysis of NDVI in Redlined Regions\n\n\nSupplement to ‘Analyzing Greenness through NDVI in Redlined areas in Philadelphia, Pennsylvania’\n\n\n\n\n\n\n\n\n\n\n\nField Methods In Hydrology - Field Report\n\n\nWriting Sample\n\n\n\n\n\n\n\n\n\n\n\nMap Gallery\n\n\nCollection of maps from undergrad.\n\n\n\n\n\n\n\n\n\n\n\nBurn Severity with Sentinel-2 data using Google Earth Engine\n\n\nPython Work from Jupyter Notebook\n\n\n\n\n\n\n\n\n\n\n\nRemote Sensing of Chlorophyll-a Using Landsat 8\n\n\nOcean remote sensing project extending analysis of Santa Monica Bay Chlorophyll-a from Trinh et al. 2017 covering catastrophic failure of Hyperion Treatment Plant in 2020\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "resume",
    "section": "",
    "text": "Download Resume Here"
  },
  {
    "objectID": "resume.html#masters-capstone-project---informing-forest-conservation-regulations-in-paraguay-122present",
    "href": "resume.html#masters-capstone-project---informing-forest-conservation-regulations-in-paraguay-122present",
    "title": "resume",
    "section": "Master’s Capstone Project - Informing Forest Conservation Regulations in Paraguay (1/22–Present)",
    "text": "Master’s Capstone Project - Informing Forest Conservation Regulations in Paraguay (1/22–Present)\nClient: Paraguay National Forest Institute; Dr. Robert Heilmayr | Role: Machine Learning Engineer\n• Assessed land use plan compliance and deforestation rates in the Paraguayan Chaco, determining that 78% of properties exhibited land use compliance utilizing geospatial overlays.\n• Developed a law-based geospatial simulation tool in R to estimate protected forest area under different laws in the undeveloped Chaco region, observing a difference of 3,397,183 ha between the least and most stringent scenarios.\n• Created a Random Forest model and Google Earth Engine workflow in Python for data acquisition and preprocessing, predicting future deforestation patterns and generating pixel-wise probabilities of near-future deforestation.\n• Supplied an interactive Shiny dashboard for stakeholders to examine results, guiding informed decisions on forest conservation and land use policies."
  },
  {
    "objectID": "resume.html#geospatial-data-science-projects",
    "href": "resume.html#geospatial-data-science-projects",
    "title": "resume",
    "section": "GEOSPATIAL & DATA SCIENCE PROJECTS",
    "text": "GEOSPATIAL & DATA SCIENCE PROJECTS\n\nBurn Severity with Sentinel-2 data using Google Earth Engine | Working with Environmental Data (12/22)\n• Burn severity analysis of the August Complex Fire using Sentinel-2 Image Collection and MTBS Feature Collection.\n• Utilized Google Earth Engine and Python to process and visualize the difference normalized burn ratio (DNBR) by severity class.\n• Leveraged the GEE platform to process and analyze large-scale satellite data efficiently and effectively.\n\n\nStatistical Analysis of NDVI in Redlined Regions | Statistics for Environmental Data Science (11/22)\n• Conducted data wrangling and exploratory data analysis (EDA) using tidy format in R.\n• Conducted statistical analysis of NDVI data in redlined regions using Log-Log Ordinary Least Squares Regression and hypothesis testing to draw informed conclusions on non-linear relationships.\n• Interpreted regression coefficients to understand the impact of individual variables on overall outcome.\n\n\nAnalyzing Greenness through NDVI in Redlined areas in Philadelphia, PA | Undergraduate Thesis (4/22–6/22)\n• Pre-process Landsat 8 OLI satellite data using RStudio to crop, mask, reclassify, and NDVI calculation.\n• Conducted QGIS processing to calculate NDVI, zonal statistics, and write memory function.\n• Integrated census median income data, NDVI data, and Redline data through QGIS and Excel.\n\n\nLogistics Experience\n\n\nGeneral Warehouse Worker – Best Buy, Los Angeles, CA (9/18/-9/21)\n• Ensures daily home deliveries for all Southern California locations are correctly loaded.\n• Safeguard that defective and returned products are accurately processed and prepped for relocation.\n• Routes orders by locating the specified product and moving it to the loading dock\n\n\nSWAT Inventory Specialist – Best Buy, Los Angeles, CA (5/2010 – 11/2015)\n• Responsible for counting assigned product counts, entering counts into RSS, researching variances, and reporting discrepancies to management. Oversaw and prepared for annual physical inventory and assisted in post physical inventory reconciliation.\n• Supported senior management by delivering reports outlining performance to drive process improvements.\n• Coached employees around shrink trends and behaviors by communicating and coaching store employees and leadership on the importance of inventory integrity and any identified process gaps)\n\n\n\nAdditional Education\n\nEl Camino Community College\n(June 2020)\nEl Camino College Foundation - Scholarship\nAssociate of Science in Physics for Transfer\nAssociate of Science in Mathematics for Transfer\nAssociate of Science in General Science – Honors\nAssociate of Arts in General Arts - Honors Associate of Arts in General Studies Biology and Physical Science"
  }
]